{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup for the colab\n",
    "\n",
    "# import os\n",
    "# os.environ['KAGGLE_USERNAME'] = \"kirillfedyanin\"\n",
    "# os.environ['KAGGLE_KEY'] = \"\"\n",
    "# !pip install imageio\n",
    "# !pip install keras \n",
    "# !pip install kaggle\n",
    "\n",
    "# !kaggle competitions download -c tgs-salt-identification-challenge\n",
    "# !mkdir -p test\n",
    "# !mkdir -p train\n",
    "# !unzip test.zip -d test\n",
    "# !unzip train.zip -d train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 101, 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "train_path = os.path.join(root_path, \"train\")\n",
    "\n",
    "def get_image(file_id):\n",
    "    image_path = os.path.join(train_path, \"images\", file_id + '.png')\n",
    "    image = np.array(imageio.imread(image_path), dtype=np.uint8)\n",
    "    return image\n",
    "\n",
    "def get_mask(file_id):\n",
    "    mask_path = os.path.join(train_path, \"masks\", file_id + '.png')\n",
    "    mask = np.array(imageio.imread(mask_path), dtype=np.uint8)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train.csv')\n",
    "file_list = list(train_values['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasearch\n",
    "Do some data digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string):\n",
    "    if isinstance(rle_string, float) and np.isnan(rle_string):\n",
    "        return np.zeros((HEIGHT, WIDTH)) \n",
    "    rle_numbers = [int(num) for num in rle_string.split()] \n",
    "    rle_pairs = np.array(rle_numbers).reshape((-1, 2))\n",
    "    \n",
    "    mask = np.zeros(HEIGHT*WIDTH)\n",
    "    for start, length in rle_pairs:\n",
    "        mask[start-1: start-1+length] = 255\n",
    "    \n",
    "    mask = mask.reshape((HEIGHT, WIDTH)).T\n",
    "        \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if masks correctly oriented\n",
    "for _ in range(15):\n",
    "    i = random.randint(0, len(dataset)-1) \n",
    "    file_id = file_list[i]\n",
    "    image, mask = get_image(file_id), get_mask(file_id)\n",
    "    f, axarr = plt.subplots(1, 3)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[1].imshow(mask, cmap='gray')\n",
    "    axarr[2].imshow(rle_to_mask(train_values['rle_mask'][i]), cmap='gray')\n",
    "    print(i, 'is correct: ', (mask==rle_to_mask(train_values['rle_mask'][i])).all())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(\"depths.csv\")\n",
    "\n",
    "train_values['depths'] = depths['z']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(train_values['depths'], bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = HEIGHT * WIDTH * 255.0\n",
    "def salt_concentration(mask):\n",
    "    return np.sum(mask)/norm\n",
    "\n",
    "masks = [get_mask(file_id) for file_id in train_values['id']]\n",
    "train_values['salt_concentration'] = [salt_concentration(mask) for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_values.merge(depths, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(train_val['salt_concentration'], train_val['depths'])\n",
    "plt.title(\"Depths vs salt concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training itself\n",
    "\n",
    "**what to do**\n",
    "- dropout\n",
    "- model saving\n",
    "- postprocess\n",
    "- unet connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, UpSampling2D, MaxPooling2D, concatenate, ZeroPadding2D, Cropping2D\n",
    "from keras.models import Model\n",
    "\n",
    "def salt_detector():\n",
    "    common_atr = {'activation': 'relu', 'padding': 'same'}\n",
    "    \n",
    "    input_image = Input(shape=(101, 101, 1))\n",
    "    x = ZeroPadding2D(((0, 27), (0, 27)))(input_image)\n",
    "    conv1 = Conv2D(16, (3, 3), **common_atr)(x)\n",
    "    conv1 = Conv2D(16, (3, 3), **common_atr)(conv1)\n",
    "    max1 = MaxPooling2D((2, 2), padding='same')(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(32, (3, 3), **common_atr)(max1)\n",
    "    conv2 = Conv2D(32, (3, 3), **common_atr)(conv2)\n",
    "    max2 = MaxPooling2D((2, 2), padding='same')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(64, (3, 3), **common_atr)(max2)\n",
    "    conv3 = Conv2D(64, (3, 3), **common_atr)(conv3)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(conv3)\n",
    "    \n",
    "    conv10 = Conv2D(64, (3, 3), **common_atr)(encoded)\n",
    "    conv10 = Conv2D(64, (3, 3), **common_atr)(conv10)\n",
    "    up10 = UpSampling2D((2, 2))(conv10)\n",
    "    \n",
    "    conv11 = Conv2D(32, (3, 3), **common_atr)(up10)\n",
    "    conv11 = Conv2D(32, (3, 3), **common_atr)(conv11)\n",
    "    up11 = UpSampling2D((2, 2))(conv11)\n",
    "    \n",
    "    conv12 = Conv2D(16, (3, 3), **common_atr)(up11)\n",
    "    conv12 = Conv2D(16, (3, 3), **common_atr)(conv12)\n",
    "    up12 = UpSampling2D((2, 2))(conv12)\n",
    "    \n",
    "    conv13 = conv12 = Conv2D(16, (3, 3), **common_atr)(up12)\n",
    "    conv13 = conv12 = Conv2D(16, (3, 3), **common_atr)(conv13)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(conv13)\n",
    "    decoded_cropped = Cropping2D(((0, 27), (0, 27)))(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_image, decoded_cropped)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "detector = salt_detector()\n",
    "detector.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(images):\n",
    "    images = np.stack(images)\n",
    "    images = images[:, :, :, :1].astype('float32') / 255.\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = prepare([get_mask(file_id)[:,:,np.newaxis] for file_id in file_list])\n",
    "images = prepare([get_image(file_id) for file_id in file_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 512\n",
    "images_train, images_val = images[:-val_size], images[-val_size:]\n",
    "labels_train, labels_val = labels[:-val_size], labels[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.fit(images_train, labels_train, epochs=10, batch_size=64, shuffle=True, validation_data=(images_val, labels_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image = images[i]\n",
    "    label = labels[i]\n",
    "    prediction = detector.predict(images[i:i+1])[0]\n",
    "    _, axarr = plt.subplots(1, 3)\n",
    "    axarr[0].imshow(image[:, :, 0], cmap='gray')\n",
    "    axarr[1].imshow(label[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axarr[2].imshow(prediction[:, :, 0], cmap='gray', vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
