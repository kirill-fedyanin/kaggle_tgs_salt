{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup for the colab\n",
    "\n",
    "# import os\n",
    "# os.environ['KAGGLE_USERNAME'] = \"kirillfedyanin\"\n",
    "# os.environ['KAGGLE_KEY'] = \"\"\n",
    "# !pip install imageio\n",
    "# !pip install keras \n",
    "# !pip install kaggle\n",
    "\n",
    "# !kaggle competitions download -c tgs-salt-identification-challenge\n",
    "# !mkdir -p test\n",
    "# !mkdir -p train\n",
    "# !unzip test.zip -d test\n",
    "# !unzip train.zip -d train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import (Input, Dense, Dropout, Conv2D, UpSampling2D, MaxPooling2D, concatenate,\n",
    "                          ZeroPadding2D, Cropping2D)\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 101, 101\n",
    "HEIGHT_TARGET, WIDTH_TARGET = 128, 128\n",
    "MODEL_FILE = 'unet_basic.h5'\n",
    "SUBMISSION_FILE = 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "\n",
    "def get_image(file_id, mode='train'):\n",
    "    image_path = os.path.join(root_path, mode, \"images\", file_id + '.png')\n",
    "    image = np.array(imageio.imread(image_path), dtype=np.uint8)\n",
    "    return image[:, :, 0]\n",
    "\n",
    "def get_mask(file_id):\n",
    "    mask_path = os.path.join(root_path, \"train\", \"masks\", file_id + '.png')\n",
    "    mask = np.array(imageio.imread(mask_path), dtype=np.uint8)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train.csv')\n",
    "file_list = list(train_values['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasearch\n",
    "Do some data digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string):\n",
    "    if isinstance(rle_string, float) and np.isnan(rle_string):\n",
    "        return np.zeros((HEIGHT, WIDTH)) \n",
    "    rle_numbers = [int(num) for num in rle_string.split()] \n",
    "    rle_pairs = np.array(rle_numbers).reshape((-1, 2))\n",
    "    \n",
    "    mask = np.zeros(HEIGHT*WIDTH)\n",
    "    for start, length in rle_pairs:\n",
    "        mask[start-1: start-1+length] = 255\n",
    "    \n",
    "    mask = mask.reshape((HEIGHT, WIDTH)).T\n",
    "        \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if masks correctly oriented\n",
    "for _ in range(15):\n",
    "    i = random.randint(0, len(file_list)-1) \n",
    "    file_id = file_list[i]\n",
    "    image, mask = get_image(file_id), get_mask(file_id)\n",
    "    f, axarr = plt.subplots(1, 3)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[1].imshow(mask, cmap='gray')\n",
    "    axarr[2].imshow(rle_to_mask(train_values['rle_mask'][i]), cmap='gray')\n",
    "    print(i, 'is correct: ', (mask==rle_to_mask(train_values['rle_mask'][i])).all())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(\"depths.csv\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(depths['z'], bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = HEIGHT * WIDTH * 255.0\n",
    "def salt_concentration(mask):\n",
    "    return np.sum(mask)/norm\n",
    "\n",
    "train_values['salt_concentration'] = [salt_concentration(get_mask(file_id)) for file_id in train_values['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_values.merge(depths, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(train_val['salt_concentration'], train_val['depths'])\n",
    "plt.title(\"Depths vs salt concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training itself\n",
    "\n",
    "**what to do**\n",
    "- train_split, stratification\n",
    "- augmentation\n",
    "- deeper?\n",
    "- refactor\n",
    "- smart threshold\n",
    "- depths usage\n",
    "- normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df['image'] = [get_image(file_id)/255.0 for file_id in train_df['id']]\n",
    "train_df['mask'] = [get_mask(file_id)/255.0 for file_id in train_df['id']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def salt_detector():\n",
    "    common_atr = {'activation': 'relu', 'padding': 'same'}\n",
    "    \n",
    "    input_image = Input(shape=(128, 128, 1))\n",
    "#     x = ZeroPadding2D(((0, 27), (0, 27)))(input_image)\n",
    "    conv1 = Conv2D(16, (3, 3), **common_atr)(input_image)\n",
    "    conv1 = Conv2D(16, (3, 3), **common_atr)(conv1)\n",
    "    max1 = MaxPooling2D((2, 2), padding='same')(conv1)\n",
    "    max1 = Dropout(0.25)(max1)\n",
    "    \n",
    "    \n",
    "    conv2 = Conv2D(32, (3, 3), **common_atr)(max1)\n",
    "    conv2 = Conv2D(32, (3, 3), **common_atr)(conv2)\n",
    "    max2 = MaxPooling2D((2, 2), padding='same')(conv2)\n",
    "    max2 = Dropout(0.25)(max2)\n",
    "    \n",
    "    conv3 = Conv2D(64, (3, 3), **common_atr)(max2)\n",
    "    conv3 = Conv2D(64, (3, 3), **common_atr)(conv3)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(conv3)\n",
    "    encoded = Dropout(0.25)(encoded)\n",
    "    \n",
    "    conv10 = Conv2D(64, (3, 3), **common_atr)(encoded)\n",
    "    conv10 = Conv2D(64, (3, 3), **common_atr)(conv10)\n",
    "    \n",
    "    up11 = UpSampling2D((2, 2))(conv10)\n",
    "    merged11 = concatenate([up11, conv3], axis=3)\n",
    "    merged11 = Dropout(0.25)(merged11)\n",
    "    conv11 = Conv2D(32, (3, 3), **common_atr)(merged11)\n",
    "    conv11 = Conv2D(32, (3, 3), **common_atr)(conv11)\n",
    "    \n",
    "    up12 = UpSampling2D((2, 2))(conv11)\n",
    "    merged12 = concatenate([up12, conv2], axis=3)\n",
    "    merged12 = Dropout(0.25)(merged12)\n",
    "    conv12 = Conv2D(16, (3, 3), **common_atr)(merged12)\n",
    "    conv12 = Conv2D(16, (3, 3), **common_atr)(conv12)\n",
    "    \n",
    "    up13 = UpSampling2D((2, 2))(conv12)\n",
    "    merged13 = concatenate([up13, conv1], axis=3)\n",
    "    merged13 = Dropout(0.25)(merged13)\n",
    "    conv13 = conv12 = Conv2D(16, (3, 3), **common_atr)(merged13)\n",
    "    conv13 = conv12 = Conv2D(16, (3, 3), **common_atr)(conv13)\n",
    "    \n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(conv13)\n",
    "#     decoded_cropped = Cropping2D(((0, 27), (0, 27)))(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_image, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "detector = salt_detector()\n",
    "detector.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(img):\n",
    "    return resize(img, (HEIGHT_TARGET, WIDTH_TARGET), mode='constant', preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "def downsample(img):\n",
    "    return resize(img, (HEIGHT, WIDTH), mode='constant', preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "def prepare(images):\n",
    "    return np.array(images.map(upsample).tolist()).reshape(-1, HEIGHT_TARGET, WIDTH_TARGET, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = HEIGHT_TARGET * WIDTH_TARGET\n",
    "def salt_level(mask):\n",
    "    return np.sum(mask)/norm\n",
    "\n",
    "train_df['salt_level'] = train_df['mask'].map(salt_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_class(level):\n",
    "    for i in range(10):\n",
    "        if level < (i+1)*0.1:\n",
    "            return i\n",
    "train_df['salt_class'] = train_df['salt_level'].map(salt_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beardysome/anaconda3/envs/azulejo/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# val_size = 256 \n",
    "# images_train, images_val = prepare(train_df['image'][:-val_size]), prepare(train_df['image'][-val_size:])\n",
    "# masks_train, masks_val = prepare(train_df['mask'][:-val_size]), prepare(train_df['mask'][-val_size:])\n",
    "images_train, images_val, masks_train, masks_val = train_test_split(\n",
    "    prepare(train_df['image']), prepare(train_df['mask']),\n",
    "    test_size = 0.2, stratify=train_df['salt_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 128, 128, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.fit(images_train, masks_train,\n",
    "             epochs=1, batch_size=32, shuffle=True,\n",
    "             validation_data=(images_val, masks_val),\n",
    "             callbacks=[EarlyStopping(patience=10, verbose=1), ReduceLROnPlateau(patience=5, factor=0.1, min_lr=1e-5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models\n",
    "detector.save(os.path.join(root_path, 'models', MODEL_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(image, threshold=0.65):\n",
    "    image[image>threshold] = 1\n",
    "    image[image<=threshold] = 0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = prepare(train_df['image'][:10])\n",
    "masks = prepare(train_df['mask'][:10])\n",
    "predicted = detector.predict(images)\n",
    "for i in range(10):\n",
    "    _, axarr = plt.subplots(1, 4)\n",
    "    axarr[0].imshow(images[i][:, :, 0], cmap='gray')\n",
    "    axarr[1].imshow(masks[i][:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axarr[2].imshow(predicted[i][:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axarr[3].imshow(threshold_image(predicted[i][:, :, 0]), cmap='gray', vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rle(mask):\n",
    "    mask = mask.reshape(HEIGHT, WIDTH).T.reshape(-1)\n",
    "    \n",
    "    rle_array = []\n",
    "    white_start = 0 \n",
    "    for i, value in enumerate(mask):\n",
    "        if value == 0 and white_start:\n",
    "            rle_array.extend([white_start, i+1-white_start])\n",
    "            white_start = 0\n",
    "        elif value == 1 and not white_start:\n",
    "            white_start = i + 1\n",
    "    if white_start:\n",
    "        rle_array.extend([white_start, len(mask)+1-white_start])\n",
    "                \n",
    "    rle_encoded = ' '.join(map(str, rle_array))\n",
    "    return rle_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate rle encoder\n",
    "for some_index in range(99):\n",
    "    file_id_ = file_list[some_index]\n",
    "    msk = get_mask(file_id_) / 255.0\n",
    "    correct_mask = train_values['rle_mask'][some_index]\n",
    "    encoded = encode_rle(msk)\n",
    "    print(encoded == correct_mask or (not encoded and np.isnan(correct_mask)), end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(root_path, 'test', 'images')\n",
    "test_file_list = [os.path.splitext(file_name)[0] for file_name in os.listdir(test_path) if os.path.isfile(os.path.join(test_path, file_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = prepare(pd.Series([get_image(file_id, 'test') for file_id in test_file_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = detector.predict(test_images[:5])\n",
    "for i in range(5):\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    img = get_image(test_file_list[i], 'test')\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(threshold_image(predicted[i, :, :, 0]), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = detector.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = [downsample(mask) for mask in predicted]\n",
    "thresholded = [threshold_image(mask) for mask in downsampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_rle = [encode_rle(mask) for mask in thresholded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_rle\n",
    "f, axarr = plt.subplots(1, 5)\n",
    "for i in range(5):\n",
    "    axarr[i].imshow(thresholded[i][:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'id': test_file_list, 'rle_mask': encoded_rle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(SUBMISSION_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c tgs-salt-identification-challenge -f submission.csv -m \"Basic unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
